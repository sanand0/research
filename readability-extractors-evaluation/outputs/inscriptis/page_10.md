  Skip to main content

      In just 5 minutes help us improve arXiv:

      Annual Global Survey
      We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
      > cs > arXiv:2312.11805

          Help | Advanced Search

            All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text
        Search
            GO

          quick links

            * Login
            * Help Pages
            * About

          Computer Science > Computation and Language

          arXiv:2312.11805 (cs)
              [Submitted on 19 Dec 2023 (v1), last revised 9 May 2025 (this version, v5)]

            Title: Gemini: A Family of Highly Capable Multimodal Models

              Authors: Gemini Team Google: Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul R. Barham, Tom Hennigan, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens Meyer, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, Jack Krawczyk, Cosmo Du, Ed Chi, Heng-Tze Cheng, Eric Ni, Purvi Shah, Patrick Kane, Betty Chan, Manaal Faruqui, Aliaksei Severyn, Hanzhao Lin, YaGuang Li, Yong Cheng, Abe Ittycheriah, Mahdis Mahdieh, Mia Chen, Pei Sun, Dustin Tran, Sumit Bagri, Balaji Lakshminarayanan, Jeremiah Liu, Andras Orban, Fabian Güra, Hao Zhou, Xinying Song, Aurelien Boffy, Harish Ganapathy, Steven Zheng, HyunJeong Choe, Ágoston Weisz, Tao Zhu, Yifeng Lu, Siddharth Gopal, Jarrod Kahn, Maciej Kula, Jeff Pitman, Rushin Shah, Emanuel Taropa, Majd Al Merey, Martin Baeuml, Zhifeng Chen, Laurent El Shafey, Yujing Zhang, Olcan Sercinoglu, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr, Nikolay Savinov, Ivo Danihelka, Becca Roelofs, Anaïs White, Anders Andreassen, Tamara von Glehn, Lakshman Yagati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman, Jakub Sygnowski, Alexandre Frechette, Charlotte Smith, Laura Culp, Lev Proleev, Yi Luan, Xi Chen et al. (1251 additional authors not shown) You must enable JavaScript to view entire author list.
              View a PDF of the paper titled Gemini: A Family of Highly Capable Multimodal Models, by Gemini Team Google: Rohan Anil and 1349 other authors
            View PDF
            Abstract: This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.
                Subjects:  Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
                Cite as:   arXiv:2312.11805 [cs.CL]                                                                                           
                           (or arXiv:2312.11805v5 [cs.CL] for this version)                                                                   
                           https://doi.org/10.48550/arXiv.2312.11805                                                                          
                             Focus to learn more                                                                                              
                               arXiv-issued DOI via DataCite                                                                                  
                

            Submission history

            From: Mariko Iinuma [view email]
            [v1] Tue, 19 Dec 2023 02:39:27 UTC (26,031 KB)
            [v2] Tue, 2 Apr 2024 22:35:21 UTC (26,595 KB)
            [v3] Mon, 20 May 2024 20:05:40 UTC (26,595 KB)
            [v4] Mon, 17 Jun 2024 22:05:29 UTC (26,595 KB)
            [v5] Fri, 9 May 2025 21:04:06 UTC (26,595 KB)
            Full-text links:

            Access Paper:

                  View a PDF of the paper titled Gemini: A Family of Highly Capable Multimodal Models, by Gemini Team Google: Rohan Anil and 1349 other authors
              * View PDF
              * TeX Source
              view license
            Current browse context:
              cs.CL
              < prev | next >
              new | recent | 2023-12
              Change to browse by:
                cs
                cs.AI
                cs.CV

            References & Citations

              * NASA ADS
              * Google Scholar
              * Semantic Scholar

              1 blog link

              (what is this?)
            export BibTeX citation Loading...

                BibTeX formatted citation

                ×
                loading...
                Data provided by:

              Bookmark

            Bibliographic Tools

              Bibliographic and Citation Tools

                    Bibliographic Explorer Toggle
                    Bibliographic Explorer (What is the Explorer?)
                    Connected Papers Toggle
                    Connected Papers (What is Connected Papers?)
                    Litmaps Toggle
                    Litmaps (What is Litmaps?)
                    scite.ai Toggle
                    scite Smart Citations (What are Smart Citations?)
            Code, Data, Media

              Code, Data and Media Associated with this Article

                    alphaXiv Toggle
                    alphaXiv (What is alphaXiv?)
                    Links to Code Toggle
                    CatalyzeX Code Finder for Papers (What is CatalyzeX?)
                    DagsHub Toggle
                    DagsHub (What is DagsHub?)
                    GotitPub Toggle
                    Gotit.pub (What is GotitPub?)
                    Huggingface Toggle
                    Hugging Face (What is Huggingface?)
                    Links to Code Toggle
                    Papers with Code (What is Papers with Code?)
                    ScienceCast Toggle
                    ScienceCast (What is ScienceCast?)
            Demos

              Demos

                    Replicate Toggle
                    Replicate (What is Replicate?)
                    Spaces Toggle
                    Hugging Face Spaces (What is Spaces?)
                    Spaces Toggle
                    TXYZ.AI (What is TXYZ.AI?)
            Related Papers

              Recommenders and Search Tools

                    Link to Influence Flower
                    Influence Flower (What are Influence Flowers?)
                    Core recommender toggle
                    CORE Recommender (What is CORE?)
            About arXivLabs

                  arXivLabs: experimental projects with community collaborators

                  arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.

                  Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.

                  Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.

          Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?)
            * About
            * Help
            * Click here to contact arXiv Contact
            * Click here to subscribe Subscribe
            * Copyright
            * Privacy Policy
            * Web Accessibility Assistance

            * arXiv Operational Status
